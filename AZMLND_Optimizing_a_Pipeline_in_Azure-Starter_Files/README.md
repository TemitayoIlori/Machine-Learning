# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, I built and optimized an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**Problem Statement: 
For this project, a file was provided that contains bank marketing iformation. It cotains data about prospective customers. The target column (y) indicates if a customer subscribed to a fixed term deposit. This project will be a classication model that predicts if a customer will subscribe to a fixed term deposit with a financial institution.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was VotingEnsemble. It has AUC of 0.95021. The accuracy was 0.91627

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
I used Random sampling as a Parameter Sampler with choice of (50,100,150,200).   

In random sampling, hyperparameter values are randomly selected from the defined search space.

**What are the benefits of the parameter sampler you chose?**
The advantage of Random Sampling is that it supports early termination of low-performing runs.

**What are the benefits of the early stopping policy you chose?**
The early  stopping policy is BANDIT with a Slack factor of 0.2 and evaluation interval of 2.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

Top four features are duration nr.employed, emp.var.rate and cons.conf.idx.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Model 1: Voting Accuracy 0.91573 AUC 0.9480367
Model 2: SparseNormalizer, XGBoostClassifier Accuracy 0.91401, AUC 0.94689

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
I'm not sure

## Proof of cluster clean up
See the "Proof of Cleanup" document
